---
title: "Problem Set 9"
author: "Prof. Bisbee"
institute: "Vanderbilt University"
date: "Due Date: 2022/11/20 @ 11:59PM CST"
output:
  html_document: default
  pdf_document: default
---

## Getting Set Up

If you haven't already, create a folder for this course, and then a subfolder called `Topic10_Classification`, and two additional subfolders within `code` and `data`.

Open `RStudio` and create a new RMarkDown file (`.Rmd`) by going to `File -> New File -> R Markdown...`.
Change the title to `"DS1000: Problem Set 9"` and the author to your full name. Save this file as `[LAST NAME]_ps9.Rmd` to your `code` folder.

If you haven't already, download the `admit_data.rds` file from the course [github page](https://github.com/jbisbee1/DS1000-F2022/blob/master/Lectures/Topic10_Classification/data/admit_data.rds) and save it to your `data` folder.

All of the following questions should be answered using 

Require `tidyverse` and load the `admit_data.rds` data to `ad`. Finally, `set.seed(123)` once at the very beginning, to ensure consistency in results throughout the problem set.
```{r}
set.seed(123)
require(tidyverse)
library(scales)
ad <- readRDS(file="../data/admit_data.rds")
```


## Question 1 [4 points + 3 EC points]
Plot the univariate visualizations for `yield`, `income`, and `sat`. Justify your choices for how you are visualizing these variables. Then plot the conditional variation between `yield` and `income`, and `yield` and `sat`. Again, justify your choices and then interpret the results. Do these variables matter for `yield`?

EXTRA CREDIT (+1 point): Explain the pattern you observe in the univariate visualization of the SAT scores. What might explain this? 

EXTRA CREDIT (+2 points): Look at these same conditional relationships between `yield` and `income` and `sat`, except divide the continuous measures of `income` and `sat` into deciles using the `ntile()` function, and create a single heatmap for all three variables, where the deciles of `income` and `sat` are on the axes, and the tiles are shaded by the average attendance in each cell. Which students are most likely to attend? Which are least likely to attend? Can you determine whether income or SAT scores matter more for attendance based on this plot?

**HINTS**:

* Univariate Description [part 1](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic5_UnivariateDescription/code/Topic5_UnivariateDescription_part1_slides.html#1) and Univariate Visualization [part 2](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic6_UnivariateVisualization/code/Topic6_UnivariateVisualization_part2_slides.html#1)
* Conditional Variation [part 1](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic7_ConditionalVariation/code/Topic7_ConditionalVariation_part1_slides.html#1) and [part 2](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic7_ConditionalVariation/code/Topic7_ConditionalVariation_part2_slides.html#5)
- [Heatmap example](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic10_Classification/code/Topic10_Classification_part1_slides.html#69)

```{r}
# Univariate
ad %>%
  ggplot(aes(x = factor(yield))) +
  geom_bar() + 
  scale_x_discrete(labels = c('Did not attend','Attended')) + 
  labs(title = 'Yield Univariate Visualization',
       subtitle = 'Attendees vs Non-Attendees',
       x = 'Yield',
       y = 'Number of Students')

ad %>%
  ggplot(aes(x = income)) + 
  geom_histogram() + 
  scale_x_continuous(labels = dollar) + 
  labs(title = 'Income Univariate Visualization',
       x = 'Family Income',
       y = 'Number of Students')

ad %>%
  ggplot(aes(x = sat)) + 
  geom_histogram() + 
  labs(title = 'SAT Univariate Visualization',
       x = 'SAT Score',
       y = 'Number of Students')

# Multivariate
ad %>%
  ggplot(aes(x = income,fill = factor(yield))) + 
  geom_density(alpha = .6) + 
  scale_x_continuous(labels = dollar) + 
  scale_fill_discrete(name = 'Yield',labels = c('Did not attend','Attended')) + 
  labs(title = 'Yield vs Income',
       x = 'Family Income',
       y = 'Density')

ad %>%
  ggplot(aes(x = sat,fill = factor(yield))) + 
  geom_density(alpha = .6) + 
  scale_fill_discrete(name = 'Yield',labels = c('Did not attend','Attended')) + 
  labs(title = 'Yield vs SAT Score',
       x = 'SAT Score',
       y = 'Density')


# EC +2: Heatmap
ad %>%
  mutate(incomeDec = ntile(income,n = 10),
         satDec = ntile(sat,n= 10)) %>%
  group_by(incomeDec,satDec) %>%
  summarise(prob_attend = mean(yield)) %>%
  ggplot(aes(x = factor(incomeDec),y = factor(satDec),fill = prob_attend)) + 
  geom_tile() + 
  scale_fill_gradient(low = 'grey70',high = 'darkred',name = 'Pr(Attend)') + 
  labs(title = 'Attendance by Income and SAT Score',
       x = 'Family Income (deciles)',
       y = 'SAT Score (deciles)')
```

> - For `yield`, I chose `geom_bar` since it is a categorical measure. For `income` and `sat`, both of which are continuous measures, I chose `geom_histogram`. For both multivariate visualizations, I chose `geom_density`, coloring the distributions by `factor(yield)`. Both of these plots indicate that students with higher income and with higher SAT scores are more likely to attend the college. EC (+1 point): the histogram for `sat` exhibits clumping around SAT scores of 1000. This might reflect one of two things. (1) this might reflect grade inflation on SAT scores, wherein scores that are lower than 1000 are rounded up. (2) this might reflect a threshold for applications established by the college, meaning that students with scores lower than 1,000 might not be able to apply. EC (+2 points): Students in higher income deciles and those in higher SAT score deciles are more likely to attend. However, it appears that income matters more, since differences in SAT scores don't matter at all among the richest students. Put another way, every row (meaning SAT decile) shows differences in probability of attending based on income, whereas not every column (meaning income decile) shows differences in probability of attending based on SAT score.

## Question 2 [4 points]
Now start with the simplest way of predicting attendance: the conditional mean. Specifically, calculate declines for `income` and `sat` called `incomeDec` and `satDec` using the `ntile()` function. Then calculate the average attendance in each cell using `group_by()` and `mutate()`, and finally predict attendance as 1 if the average is greater than 0.5, and 0 otherwise, using an `ifelse()` function. Evaluate the performance in terms of **accuracy**, **sensitivity**, and **specificity**. Finally, define these terms and describe your results for a general audience reader who doesn't understand statistics.

**HINTS**:

* [Conditional means](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic10_Classification/code/Topic10_Classification_part1_slides.html#72)
* [Sensitivity & Specificity](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic10_Classification/code/Topic10_Classification_part1_slides.html#90)

```{r}
ad <- ad %>%
  mutate(incomeDec = ntile(income,n = 10),
         satDec = ntile(sat,n= 10)) %>%
  group_by(incomeDec,satDec) %>%
  mutate(prob_attend = mean(yield)) %>%
  mutate(pred_attend = ifelse(prob_attend > .5,1,0)) %>%
  ungroup()

ad %>%
  group_by(yield) %>%
  mutate(total_attend = n()) %>%
  group_by(yield,pred_attend,total_attend) %>%
  summarise(nStudents=n(),.groups = 'drop') %>%
  mutate(prop = percent(nStudents / total_attend)) %>%
  ungroup() %>%
  mutate(accuracy = percent(sum((yield == pred_attend)*nStudents) / sum(nStudents))) %>%
  filter(yield == pred_attend)
```

> - The overall accuracy -- meaning the proportion of students who we accurately predicted to either attend or not attend out of all students -- is 83%. The sensitivity -- meaning the proportion of correct predictions of attendees out of total attendees -- is 85.6%. The specificity -- meaning the proportion of correct predictions of non-attendees out of total non-attendees -- is 78.2%.

## Question 3 [4 points]
Now predict whether students will attend using a linear regression model (using the `lm()` function) that predicts `yield` as a function of `income` and `sat` (**not** using deciles, just the continuous versions). Calculate **accuracy**, **sensitivity**, and **specificity** from this model where the threshold is again 0.5, and compare to the results from Question 3. Does this model do better?

**HINTS**:

* [Linear regression for classification](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic10_Classification/code/Topic10_Classification_part1_slides.html#81)

```{r}
m1 <- lm(yield ~ income + sat,ad)

ad %>%
  mutate(pred_attend = ifelse(predict(m1) > .5,1,0)) %>%
  group_by(yield) %>%
  mutate(total_attend = n()) %>%
  group_by(yield,pred_attend,total_attend) %>%
  summarise(nStudents=n(),.groups = 'drop') %>%
  mutate(prop = percent(nStudents / total_attend)) %>%
  ungroup() %>%
  mutate(accuracy = percent(sum((yield == pred_attend)*nStudents) / sum(nStudents))) %>%
  filter(yield == pred_attend)
```

> - Using a linear regression model, we have somewhat worse accuracy of 80%. Our sensitivity has increased from 85.6% to 91.7%, meaning we are doing a better job of accurately predicting attendees. However, our specificity has declined from 78.2% down to 53.5%, meaning we are doing a much worse job of accurately predicting non-attendees.

## Question 4 [4 points]
Now recalculate **sensitivity**, **specificity**, and **accuracy** using different thresholds, ranging from 0 to 1, incrementing by 0.025 (use the `seq(from,to,by)` function). Plot the relationship between these thresholds and both the sensitivity and the specificity. What is the optimal threshold to balance the trade-off between **sensitivity** and **specificity**? Then plot ROC Curve and calculate the AUC. 

**HINTS**:

* [Threshold loop](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic10_Classification/code/Topic10_Classification_part1_slides.html#95)
* [ROC](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic10_Classification/code/Topic10_Classification_part1_slides.html#97)
* [AUC](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic10_Classification/code/Topic10_Classification_part1_slides.html#103)

```{r}
toplot <- NULL
for(thresh in seq(0,1,by = 0.025)) {
  toplot <- ad %>%
  mutate(pred_attend = ifelse(predict(m1) > thresh,1,0)) %>%
  group_by(yield) %>%
  mutate(total_attend = n()) %>%
  group_by(yield,pred_attend,total_attend) %>%
  summarise(nStudents=n(),.groups = 'drop') %>%
  mutate(prop = nStudents / total_attend) %>%
  ungroup() %>%
  mutate(accuracy = sum((yield == pred_attend)*nStudents) / sum(nStudents)) %>%
  # filter(yield == pred_attend) %>% Also possible to filter here for either specificity or sensitivity
  mutate(threshold = thresh) %>%
    bind_rows(toplot)
}

# Plot relationship between threshold and sens/spec
toplot %>%
  mutate(metric = ifelse(yield == 1 & pred_attend == 1,'Sensitivity',
                         ifelse(yield == 0 & pred_attend == 0,'Specificity',NA))) %>%
  drop_na(metric) %>%
  ggplot(aes(x = threshold,y = prop,color = metric)) + 
  geom_line() + 
  labs(title = 'Sensitivity and Specificity by Threshold',
       subtitle = 'Model: Linear Regression',
       x = 'Threshold',
       y = 'Proportion Correct',
       color = 'Metric')

# Plot ROC Curve
toplot %>%
  mutate(metric = ifelse(yield == 1 & pred_attend == 1,'Sensitivity',
                         ifelse(yield == 0 & pred_attend == 0,'Specificity',NA))) %>%
  drop_na(metric) %>%
  select(prop,metric,threshold) %>%
  spread(metric,prop) %>%
  ggplot(aes(x = 1-Specificity,y = Sensitivity)) + 
  geom_line() + 
  xlim(c(0,1)) + ylim(c(0,1)) + 
  geom_abline(slope = 1,intercept = 0,linetype = 'dotted') + 
  labs(title = 'ROC Curve',
       subtitle = 'Model: Linear Regression',
       x = '1-Specificity',
       y = 'Sensitivity')

# Calculate AUC
require(tidymodels)
roc_auc(data = ad %>%
  mutate(pred_attend = predict(m1),
         truth = factor(yield,levels = c('1','0'))) %>%
  select(truth,pred_attend),truth,pred_attend)
```

> - Based on these results, the optimal point to balance between sensitivity and specificity is at a threshold of approximately 0.60. 

## Question 5 [4 points]
Re-do questions 3 and 4 using a logistic regression. Does this perform better than a linear regression model?

**HINTS**:

* [Logit regression](https://www.jamesbisbee.com/DS1000-F2022/Lectures/Topic10_Classification/code/Topic10_Classification_part2_slides.html#35)

```{r}
m2 <- glm(yield ~ income + sat,ad,family = binomial(link = 'logit'))

ad %>%
  mutate(pred_attend = ifelse(predict(m2,type = 'response') > .5,1,0)) %>%
  group_by(yield) %>%
  mutate(total_attend = n()) %>%
  group_by(yield,pred_attend,total_attend) %>%
  summarise(nStudents=n(),.groups = 'drop') %>%
  mutate(prop = percent(nStudents / total_attend)) %>%
  ungroup() %>%
  mutate(accuracy = percent(sum((yield == pred_attend)*nStudents) / sum(nStudents))) %>%
  filter(yield == pred_attend)

toplot <- NULL
for(thresh in seq(0,1,by = 0.025)) {
  toplot <- ad %>%
  mutate(pred_attend = ifelse(predict(m2,type = 'response') > thresh,1,0)) %>%
  group_by(yield) %>%
  mutate(total_attend = n()) %>%
  group_by(yield,pred_attend,total_attend) %>%
  summarise(nStudents=n(),.groups = 'drop') %>%
  mutate(prop = nStudents / total_attend) %>%
  ungroup() %>%
  mutate(accuracy = sum((yield == pred_attend)*nStudents) / sum(nStudents)) %>%
  filter(yield == pred_attend) %>%
  mutate(threshold = thresh) %>%
    bind_rows(toplot)
}

# Plot relationship between threshold and sens/spec
toplot %>%
  mutate(metric = ifelse(yield == 1 & pred_attend == 1,'Sensitivity','Specificity')) %>%
  ggplot(aes(x = threshold,y = prop,color = metric)) + 
  geom_line() + 
  labs(title = 'Sensitivity and Specificity by Threshold',
       subtitle = 'Model: Logistic Regression',
       x = 'Threshold',
       y = 'Proportion Correct',
       color = 'Metric')

# Plot ROC Curve
toplot %>%
  mutate(metric = ifelse(yield == 1 & pred_attend == 1,'Sensitivity','Specificity')) %>%
  select(prop,metric,threshold) %>%
  spread(metric,prop) %>%
  ggplot(aes(x = 1-Specificity,y = Sensitivity)) + 
  geom_line() + 
  xlim(c(0,1)) + ylim(c(0,1)) + 
  geom_abline(slope = 1,intercept = 0,linetype = 'dotted') + 
  labs(title = 'ROC Curve',
       subtitle = 'Model: Logistic Regression',
       x = '1-Specificity',
       y = 'Sensitivity')

# Calculate AUC
require(tidymodels)
roc_auc(data = ad %>%
  mutate(pred_attend = predict(m2,type = 'response'),
         truth = factor(yield,levels = c('1','0'))) %>%
  select(truth,pred_attend),truth,pred_attend)
```

> - Using a logistic regression model, we have an accuracy of 83% which is better than our linear regression model overall. However, our sensitivity has decreased from 91.7% to 88%, meaning we are doing a worse job of accurately predicting attendees. But our specificity has increased from 53.5% to 72%, meaning we are doing a better job of accurately predicting non-attendees. The optimal threshold is again approximately 0.60.

## Question 6  [4 extra credit points]

Now redo questions 3 and 4 using a random forest via the `ranger` package. Interpret the results. Why should we not be over-excited by the AUC in this approach? What might you do to fix this issue?

```{r}
require(ranger)
m3 <- ranger(yield ~ sat + income,ad)

preds <- predict(m3,data = ad)

ad %>%
  mutate(pred_attend = ifelse(preds$predictions > .5,1,0)) %>%
  group_by(yield) %>%
  mutate(total_attend = n()) %>%
  group_by(yield,pred_attend,total_attend) %>%
  summarise(nStudents=n(),.groups = 'drop') %>%
  mutate(prop = percent(nStudents / total_attend)) %>%
  ungroup() %>%
  mutate(accuracy = percent(sum((yield == pred_attend)*nStudents) / sum(nStudents))) %>%
  filter(yield == pred_attend)

toplot <- NULL
for(thresh in seq(0,1,by = 0.025)) {
  toplot <- ad %>%
  mutate(pred_attend = ifelse(preds$predictions > thresh,1,0)) %>%
  group_by(yield) %>%
  mutate(total_attend = n()) %>%
  group_by(yield,pred_attend,total_attend) %>%
  summarise(nStudents=n(),.groups = 'drop') %>%
  mutate(prop = nStudents / total_attend) %>%
  ungroup() %>%
  mutate(accuracy = sum((yield == pred_attend)*nStudents) / sum(nStudents)) %>%
  filter(yield == pred_attend) %>%
  mutate(threshold = thresh) %>%
    bind_rows(toplot)
}

# Plot relationship between threshold and sens/spec
toplot %>%
  mutate(metric = ifelse(yield == 1 & pred_attend == 1,'Sensitivity','Specificity')) %>%
  ggplot(aes(x = threshold,y = prop,color = metric)) + 
  geom_line() + 
  labs(title = 'Sensitivity and Specificity by Threshold',
       subtitle = 'Model: Random Forest',
       x = 'Threshold',
       y = 'Proportion Correct',
       color = 'Metric')

# Plot ROC Curve
toplot %>%
  mutate(metric = ifelse(yield == 1 & pred_attend == 1,'Sensitivity','Specificity')) %>%
  select(prop,metric,threshold) %>%
  spread(metric,prop) %>%
  ggplot(aes(x = 1-Specificity,y = Sensitivity)) + 
  geom_line() + 
  xlim(c(0,1)) + ylim(c(0,1)) + 
  geom_abline(slope = 1,intercept = 0,linetype = 'dotted') + 
  labs(title = 'ROC Curve',
       subtitle = 'Model: Random Forest',
       x = '1-Specificity',
       y = 'Sensitivity')

# Calculate AUC
roc_auc(data = ad %>%
  mutate(pred_attend = preds$predictions,
         truth = factor(yield,levels = c('1','0'))) %>%
  select(truth,pred_attend),truth,pred_attend)

# CV for AUC
cvRes <- NULL
for(i in 1:100) {
  inds <- sample(1:nrow(ad),size = round(nrow(ad)*.8),replace = F)
  train <- ad %>%
    slice(inds)
  test <- ad %>%
    slice(-inds)
  
  mTmp <- ranger(yield ~ sat + income,train)

  preds <- predict(mTmp,data = test)
  
  
  cvRes <- roc_auc(data = test %>%
    mutate(pred_attend = preds$predictions,
           truth = factor(yield,levels = c('1','0'))) %>%
    select(truth,pred_attend),truth,pred_attend) %>%
    mutate(cvInd = i) %>%
    bind_rows(cvRes)
}

cvRes %>%
  summarise(cv_auc = mean(.estimate))
```

> - The random forest results are incredibly strong, with an AUC of 0.9999 compared to values of 0.89 (logistic) and 0.87 (linear). However, we should immediately be concerned with **overfitting** based on these results. They simply appear to be too good for the data. To confirm, we can re-calculate the AUC using cross validation, resulting in a much more modest 0.88 AUC, or in between the logit and linear regression results. THERE IS NO SUCH THING AS A MAGIC SOLUTION!